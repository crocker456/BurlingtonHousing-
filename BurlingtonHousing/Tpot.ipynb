{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burlington TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btvFucntions import parse_btv_props\n",
    "#for tablular data managment \n",
    "import pandas as pd \n",
    "#for scientific plotting \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT \n",
    "\n",
    "TPOT is a genetic algorithm that creates optimized sklearn pipelines auotmatically.  I have already identified a pipeline that works quite well to predict housing prices but I'd like to see how this compares to what TPOT finds. \n",
    "\n",
    "In addititon, TPOT might discover some additional preprocessing steps that may help to improve prediction. The package itself has many different modules that are not documented in the API for building models. It is pretty clear typically how to use them though based on the code generated by TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (4605, 45)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eed3b750ac64cf2b4cdef6c43581ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=420, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -2763194709.8879194\n",
      "Generation 2 - Current best internal CV score: -2755283429.436372\n",
      "Generation 3 - Current best internal CV score: -2755283429.436372\n",
      "Generation 4 - Current best internal CV score: -2753376551.2473683\n",
      "Generation 5 - Current best internal CV score: -2680936547.471691\n",
      "Generation 6 - Current best internal CV score: -2632685431.529882\n",
      "Generation 7 - Current best internal CV score: -2632685431.529882\n",
      "Generation 8 - Current best internal CV score: -2632685431.529882\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(GradientBoostingRegressor(input_matrix, alpha=0.8, learning_rate=0.001, loss=huber, max_depth=7, max_features=0.8500000000000001, min_samples_leaf=16, min_samples_split=16, n_estimators=100, subsample=0.8)), l1_ratio=0.9500000000000001, tol=0.001)\n",
      "-6574731662.282968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look to btvFunctions.py for code used to parse in the data and create the model matrix\n",
    "# This function is contained in a seperate .py file to keep it from taking up too much space in the notebook\n",
    "# This also helps with code organization\n",
    "df = parse_btv_props()\n",
    "\n",
    "\n",
    "df['SaleDate'] = pd.to_datetime(df['SaleDate'])\n",
    "modeldf = df.drop(['AccountNumber', 'ParcelID', 'SpanNumber', 'StreetNumber',\n",
    "       'AlternateNumber', 'Unit', 'CuO1LastName',\n",
    "       'CuO1FirstName', 'CuO2LastName', 'CuO2FirstName', 'CuO3LastName',\n",
    "       'CuO3FirstName','LegalReference', 'GrantorLastName', 'FID', 'Baths'], axis = 1)\n",
    "modeldf['Latitude'] = pd.to_numeric(modeldf['Latitude'])\n",
    "modeldf['Longitude'] = pd.to_numeric(modeldf['Longitude'])\n",
    "#modeldf['Sale_Year'] = modeldf['SaleDate'].apply(lambda row: row.year)\n",
    "modeldf.drop('SaleDate', axis=1, inplace= True)\n",
    "modeldf = modeldf[(modeldf['LandUse'] == \"Single Family\") | (modeldf['LandUse'] == \"Residential Condo\")]\n",
    "modeldf = modeldf[modeldf['SalePrice']> 0]\n",
    "modeldf.dropna(inplace = True)\n",
    "#pulled cityhall gps coords from this https://www.maps.ie/coordinates.html\n",
    "from geopy.distance import great_circle\n",
    "distances = []\n",
    "for i, j in zip(modeldf['Latitude'], modeldf['Longitude']):\n",
    "    val = (i, j)\n",
    "    Cityhall = (44.47647568031712, -73.21353835752235)\n",
    "    dist = great_circle(val,Cityhall).miles\n",
    "    distances.append(dist)\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "modeldf = pd.get_dummies(modeldf)\n",
    "target_name = 'SalePrice'\n",
    "y=modeldf[target_name]\n",
    "Xframe = modeldf.drop(['SalePrice'], axis=1)\n",
    "data_names = Xframe.columns\n",
    "X = Xframe.copy()\n",
    "# create train-test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "imp = SimpleImputer(strategy = 'median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "tpot = TPOTRegressor(generations=20, population_size=20, verbosity=2, use_dask=True, n_jobs= -1)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('btv_model.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
